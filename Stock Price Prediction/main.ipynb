{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"5876a7de43a49430ea786fae7d255a3d103e60d8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       Adj Close      Close       High        Low       Open     Volume\n",
      "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL       AAPL\n",
      "Date                                                                        \n",
      "2020-01-02  72.796013  75.087502  75.150002  73.797501  74.059998  135480400\n",
      "2020-01-03  72.088287  74.357498  75.144997  74.125000  74.287498  146322800\n",
      "2020-01-06  72.662712  74.949997  74.989998  73.187500  73.447502  118387200\n",
      "2020-01-07  72.320976  74.597504  75.224998  74.370003  74.959999  108872000\n",
      "2020-01-08  73.484352  75.797501  76.110001  74.290001  74.290001  132079200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Fetch data for Apple (AAPL)\n",
    "df = yf.download('AAPL', start='2020-01-01', end='2024-11-23')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1233 entries, 2020-01-02 to 2024-11-22\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   (Adj Close, AAPL)  1233 non-null   float64\n",
      " 1   (Close, AAPL)      1233 non-null   float64\n",
      " 2   (High, AAPL)       1233 non-null   float64\n",
      " 3   (Low, AAPL)        1233 non-null   float64\n",
      " 4   (Open, AAPL)       1233 non-null   float64\n",
      " 5   (Volume, AAPL)     1233 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 67.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticker</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>72.79601287841797</td>\n",
       "      <td>75.0875015258789</td>\n",
       "      <td>75.1500015258789</td>\n",
       "      <td>73.79750061035156</td>\n",
       "      <td>74.05999755859375</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>72.08828735351562</td>\n",
       "      <td>74.35749816894531</td>\n",
       "      <td>75.1449966430664</td>\n",
       "      <td>74.125</td>\n",
       "      <td>74.2874984741211</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>72.66271209716797</td>\n",
       "      <td>74.94999694824219</td>\n",
       "      <td>74.98999786376953</td>\n",
       "      <td>73.1875</td>\n",
       "      <td>73.44750213623047</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price          Adj Close              Close               High  \\\n",
       "0      Ticker               AAPL               AAPL               AAPL   \n",
       "1        Date                NaN                NaN                NaN   \n",
       "2  2020-01-02  72.79601287841797   75.0875015258789   75.1500015258789   \n",
       "3  2020-01-03  72.08828735351562  74.35749816894531   75.1449966430664   \n",
       "4  2020-01-06  72.66271209716797  74.94999694824219  74.98999786376953   \n",
       "\n",
       "                 Low               Open     Volume  \n",
       "0               AAPL               AAPL       AAPL  \n",
       "1                NaN                NaN        NaN  \n",
       "2  73.79750061035156  74.05999755859375  135480400  \n",
       "3             74.125   74.2874984741211  146322800  \n",
       "4            73.1875  73.44750213623047  118387200  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([0,1],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>72.79601287841797</td>\n",
       "      <td>75.0875015258789</td>\n",
       "      <td>75.1500015258789</td>\n",
       "      <td>73.79750061035156</td>\n",
       "      <td>74.05999755859375</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>72.08828735351562</td>\n",
       "      <td>74.35749816894531</td>\n",
       "      <td>75.1449966430664</td>\n",
       "      <td>74.125</td>\n",
       "      <td>74.2874984741211</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>72.66271209716797</td>\n",
       "      <td>74.94999694824219</td>\n",
       "      <td>74.98999786376953</td>\n",
       "      <td>73.1875</td>\n",
       "      <td>73.44750213623047</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>72.32097625732422</td>\n",
       "      <td>74.59750366210938</td>\n",
       "      <td>75.2249984741211</td>\n",
       "      <td>74.37000274658203</td>\n",
       "      <td>74.95999908447266</td>\n",
       "      <td>108872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>73.4843521118164</td>\n",
       "      <td>75.79750061035156</td>\n",
       "      <td>76.11000061035156</td>\n",
       "      <td>74.29000091552734</td>\n",
       "      <td>74.29000091552734</td>\n",
       "      <td>132079200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price          Adj Close              Close               High  \\\n",
       "2  2020-01-02  72.79601287841797   75.0875015258789   75.1500015258789   \n",
       "3  2020-01-03  72.08828735351562  74.35749816894531   75.1449966430664   \n",
       "4  2020-01-06  72.66271209716797  74.94999694824219  74.98999786376953   \n",
       "5  2020-01-07  72.32097625732422  74.59750366210938   75.2249984741211   \n",
       "6  2020-01-08   73.4843521118164  75.79750061035156  76.11000061035156   \n",
       "\n",
       "                 Low               Open     Volume  \n",
       "2  73.79750061035156  74.05999755859375  135480400  \n",
       "3             74.125   74.2874984741211  146322800  \n",
       "4            73.1875  73.44750213623047  118387200  \n",
       "5  74.37000274658203  74.95999908447266  108872000  \n",
       "6  74.29000091552734  74.29000091552734  132079200  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data.reset_index()['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1233,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         75.0875015258789\n",
       "1        74.35749816894531\n",
       "2        74.94999694824219\n",
       "3        74.59750366210938\n",
       "4        75.79750061035156\n",
       "               ...        \n",
       "1228    228.02000427246094\n",
       "1229    228.27999877929688\n",
       "1230                 229.0\n",
       "1231    228.52000427246094\n",
       "1232     229.8699951171875\n",
       "Name: Close, Length: 1233, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "df1 = scalar.fit_transform(np.array(df2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1053011 ],\n",
       "       [0.10125424],\n",
       "       [0.10453883],\n",
       "       ...,\n",
       "       [0.95853374],\n",
       "       [0.95587282],\n",
       "       [0.96335666]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(df1)*0.65)\n",
    "test_size = len(df1) - training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df1[0:training_size,:], df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 432)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step):\n",
    "    dataX, dataY =[],[]\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i+time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1053011 , 0.10125424, 0.10453883, ..., 0.12816854, 0.1309958 ,\n",
       "        0.12800224],\n",
       "       [0.10125424, 0.10453883, 0.10258474, ..., 0.1309958 , 0.12800224,\n",
       "        0.12991476],\n",
       "       [0.10453883, 0.10258474, 0.10923707, ..., 0.12800224, 0.12991476,\n",
       "        0.1301088 ],\n",
       "       ...,\n",
       "       [0.46565033, 0.46747974, 0.45949691, ..., 0.50622968, 0.49458804,\n",
       "        0.49791425],\n",
       "       [0.46747974, 0.45949691, 0.45594899, ..., 0.49458804, 0.49791425,\n",
       "        0.52629756],\n",
       "       [0.45949691, 0.45594899, 0.48172688, ..., 0.49791425, 0.52629756,\n",
       "        0.54181972]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12991476, 0.1301088 , 0.12967918, 0.13509807, 0.13716306,\n",
       "       0.13962997, 0.13574945, 0.14847205, 0.15118841, 0.16578199,\n",
       "       0.17804726, 0.15457002, 0.15858914, 0.16439609, 0.17699396,\n",
       "       0.17631488, 0.17650893, 0.17372325, 0.18640427, 0.19702031,\n",
       "       0.1880535 , 0.19467813, 0.17914214, 0.19043726, 0.19462268,\n",
       "       0.1936664 , 0.1936664 , 0.20716515, 0.20555749, 0.21758714,\n",
       "       0.21986005, 0.22078858, 0.21833554, 0.22709448, 0.23079482,\n",
       "       0.22412862, 0.22304761, 0.23430116, 0.2267757 , 0.22828633,\n",
       "       0.20374196, 0.20246691, 0.21463516, 0.20600099, 0.21591021,\n",
       "       0.22228538, 0.27810965, 0.29295268, 0.29698567, 0.29918926,\n",
       "       0.32047674, 0.30501008, 0.31396301, 0.29537802, 0.31552909,\n",
       "       0.32661634, 0.32604811, 0.32438501, 0.32967918, 0.33048298,\n",
       "       0.34471626, 0.37850464, 0.38675075, 0.38102695, 0.39043726,\n",
       "       0.38205255, 0.38092997, 0.4043933 , 0.43288751, 0.41747625,\n",
       "       0.35915737, 0.35960087, 0.31447579, 0.33942209, 0.31819001,\n",
       "       0.30993002, 0.3285566 , 0.32955445, 0.31065068, 0.30072759,\n",
       "       0.28132492, 0.29928628, 0.30887672, 0.28287717, 0.28897514,\n",
       "       0.31148223, 0.32633914, 0.32151617, 0.33105121, 0.33648398,\n",
       "       0.3155845 , 0.33487632, 0.31636064, 0.32700439, 0.32639459,\n",
       "       0.33748183, 0.37867094, 0.36037697, 0.36087592, 0.35821496,\n",
       "       0.34884623, 0.33199366, 0.34047539, 0.33692748, 0.3307186 ,\n",
       "       0.32678264, 0.32683809, 0.33543067, 0.30549511, 0.32833485,\n",
       "       0.29252306, 0.29202411, 0.30128199, 0.32628369, 0.34890168,\n",
       "       0.34701686, 0.33387847, 0.33193821, 0.35145174, 0.34989953,\n",
       "       0.35017673, 0.3559421 , 0.35089738, 0.34335805, 0.34673967,\n",
       "       0.33953294, 0.32018572, 0.32750329, 0.33227081, 0.33537523,\n",
       "       0.34901257, 0.36935765, 0.37135336, 0.37057726, 0.36675214,\n",
       "       0.37506758, 0.37856004, 0.36414663, 0.37224032, 0.36763914,\n",
       "       0.36414663, 0.39796272, 0.39757467, 0.40250849, 0.39119953,\n",
       "       0.39990298, 0.42013725, 0.41503712, 0.42063615, 0.44680205,\n",
       "       0.43671262, 0.43033749, 0.42462757, 0.40644449, 0.41531424,\n",
       "       0.39086689, 0.41481533, 0.42107965, 0.40406069, 0.40306288,\n",
       "       0.41464903, 0.40367268, 0.39386045, 0.39768556, 0.42096875,\n",
       "       0.44779986, 0.4599959 , 0.48133879, 0.48266929, 0.47657127,\n",
       "       0.44901947, 0.42058075, 0.4326658 , 0.43737791, 0.43155709,\n",
       "       0.45068257, 0.44719006, 0.44802165, 0.44303234, 0.43959533,\n",
       "       0.43815402, 0.43948443, 0.42739938, 0.41437183, 0.4081076 ,\n",
       "       0.40899451, 0.38754072, 0.38676462, 0.38393736, 0.35976717,\n",
       "       0.36126397, 0.39746381, 0.38266235, 0.36569884, 0.35499965,\n",
       "       0.36215093, 0.33410022, 0.36032152, 0.35416814, 0.36514449,\n",
       "       0.35998892, 0.37639803, 0.38515697, 0.38066665, 0.35721711,\n",
       "       0.35422355, 0.37307187, 0.3683598 , 0.3547779 , 0.35754971,\n",
       "       0.36098677, 0.36198463, 0.35372464, 0.36619779, 0.37090986,\n",
       "       0.38698637, 0.38870488, 0.39807361, 0.41171092, 0.42634607,\n",
       "       0.41658933, 0.43427341, 0.42096875, 0.43466151, 0.4327767 ,\n",
       "       0.43654632, 0.42695588, 0.42911789, 0.42046985, 0.4336637 ,\n",
       "       0.43588111, 0.4340517 , 0.42956139, 0.42900699, 0.41780893,\n",
       "       0.42379597, 0.39779642, 0.39918236, 0.4082739 , 0.41087941,\n",
       "       0.39225279, 0.38704182, 0.36963481, 0.3818308 , 0.39557896,\n",
       "       0.38903748, 0.38116555, 0.38027859, 0.39480285, 0.38438086,\n",
       "       0.3936387 , 0.39252999, 0.39225279, 0.38354931, 0.37983509,\n",
       "       0.37800569, 0.38232971, 0.37390342, 0.38693092, 0.38698637,\n",
       "       0.39164299, 0.393805  , 0.38815053, 0.3950246 , 0.41237612,\n",
       "       0.4077195 , 0.41054672, 0.41963826, 0.41226531, 0.42246556,\n",
       "       0.4317788 , 0.43022659, 0.42861898, 0.42695588, 0.43621371,\n",
       "       0.44480634, 0.44829885, 0.45001736, 0.46492972, 0.47634956,\n",
       "       0.49048582, 0.48311279, 0.49347933, 0.49009772, 0.49641745,\n",
       "       0.51587553, 0.51216131, 0.50057516, 0.47873328, 0.49924466,\n",
       "       0.49508695, 0.50284807, 0.51260481, 0.51498861, 0.50268177,\n",
       "       0.49275864, 0.49641745, 0.49763705, 0.49575224, 0.50595248,\n",
       "       0.50367958, 0.50428938, 0.49918926, 0.49891206, 0.49619574,\n",
       "       0.49763705, 0.51443422, 0.51559841, 0.52679647, 0.52164094,\n",
       "       0.50040886, 0.50229367, 0.5105537 , 0.51898003, 0.51848104,\n",
       "       0.5114961 , 0.50695029, 0.5128266 , 0.53788371, 0.53073248,\n",
       "       0.5345021 , 0.54082182, 0.54442523, 0.55767448, 0.54891555,\n",
       "       0.54315022, 0.51487772, 0.51809303, 0.5101656 , 0.51521032,\n",
       "       0.51387982, 0.49874576, 0.48144969, 0.48416601, 0.49758164,\n",
       "       0.50301437, 0.50351328, 0.49492064, 0.47573976, 0.48083988,\n",
       "       0.47346686, 0.47984199, 0.46038391, 0.47130485, 0.47623867,\n",
       "       0.4833899 , 0.48122789, 0.48072899, 0.47352226, 0.47019614,\n",
       "       0.48599541, 0.49198253, 0.50146216, 0.51371352, 0.51648533,\n",
       "       0.51770493, 0.51332551, 0.51304831, 0.51681802, 0.51421251,\n",
       "       0.53483479, 0.51947893, 0.51482231, 0.52069854, 0.52884767,\n",
       "       0.52590955, 0.52768347, 0.52302685, 0.52507796, 0.5090569 ,\n",
       "       0.5087797 , 0.52053223, 0.52058764, 0.52613126, 0.53993491,\n",
       "       0.56421591, 0.57907286, 0.58167837, 0.58384038, 0.58677849,\n",
       "       0.55833969, 0.57735435, 0.60540506, 0.60246695, 0.59686784,\n",
       "       0.5862241 , 0.60551596, 0.6380015 , 0.65962168, 0.65673897,\n",
       "       0.68384727, 0.66328049, 0.65546396, 0.68301577, 0.64398862,\n",
       "       0.63777979, 0.63007416, 0.64803553, 0.66272609, 0.666274  ,\n",
       "       0.68872569, 0.68296027, 0.68345927, 0.67691775, 0.67342532,\n",
       "       0.69803893, 0.68523318, 0.65873468, 0.64254731, 0.64348972,\n",
       "       0.64360061, 0.65962168, 0.66211629, 0.64360061, 0.64847903,\n",
       "       0.63035136, 0.61056059, 0.60102556, 0.589384  , 0.58500449,\n",
       "       0.57480425, 0.57430534, 0.57169984, 0.63328947, 0.65795857,\n",
       "       0.65701617, 0.6638348 , 0.64753654, 0.64470932, 0.6406625 ,\n",
       "       0.65823577, 0.666274  , 0.64321252, 0.62392074, 0.62525124,\n",
       "       0.64692674, 0.64559632, 0.62525124, 0.61649231, 0.59997234,\n",
       "       0.57641195, 0.59121341, 0.60291045, 0.60440717, 0.59376343,\n",
       "       0.61239   , 0.61056059, 0.59359712, 0.57214334, 0.5618322 ,\n",
       "       0.59237752, 0.56781932, 0.54680895, 0.52402466, 0.54880465,\n",
       "       0.57375095, 0.57946087, 0.59808744, 0.60584856, 0.62491864,\n",
       "       0.63262427, 0.65402265, 0.65762597, 0.66250438, 0.68113095,\n",
       "       0.67453403, 0.65701617, 0.65535306, 0.67824825, 0.65951078,\n",
       "       0.64160491, 0.64332342, 0.63195897, 0.60789968, 0.61848801,\n",
       "       0.63367748, 0.60534957, 0.60413006, 0.61704662, 0.61610421,\n",
       "       0.61161389, 0.5859469 , 0.59198951, 0.55828428, 0.55700927,\n",
       "       0.59620263, 0.56299631, 0.5647149 , 0.57314115, 0.60939648,\n",
       "       0.55811798, 0.5609452 , 0.53200749, 0.54558934, 0.50118496,\n",
       "       0.47934308, 0.50456658, 0.49586305, 0.51637452, 0.46969723,\n",
       "       0.45046086, 0.45179128, 0.48239209, 0.46714713, 0.46803413,\n",
       "       0.48610631, 0.51859193, 0.51415702, 0.5134364 , 0.52729546,\n",
       "       0.49497614, 0.49918926, 0.5134364 , 0.50927869, 0.47978658,\n",
       "       0.44924126, 0.42013725, 0.42501557, 0.43981703, 0.41004781,\n",
       "       0.41836325, 0.44225624, 0.43937362, 0.45556098, 0.47435386,\n",
       "       0.47435386, 0.45095977, 0.46088281, 0.44696835, 0.45921971,\n",
       "       0.47379946, 0.48133879, 0.50035345, 0.50417848, 0.49214883,\n",
       "       0.49763705, 0.49558594, 0.51210591, 0.52153004, 0.50434487,\n",
       "       0.52613126, 0.53744021, 0.55024605, 0.54326103, 0.53694131,\n",
       "       0.52945747, 0.55822879, 0.56133329, 0.58993831, 0.58439469,\n",
       "       0.57607926, 0.61000628, 0.60823228, 0.60568226, 0.60302126,\n",
       "       0.60329846, 0.62724695, 0.62308923, 0.64310171, 0.64914423,\n",
       "       0.64825723, 0.65668356, 0.65446606, 0.6398864 , 0.61798911,\n",
       "       0.61610421, 0.61776732, 0.63162637, 0.59609174, 0.58367408,\n",
       "       0.56998133, 0.56061259, 0.5647149 , 0.55279607, 0.54570024,\n",
       "       0.55362766, 0.54531223, 0.5614441 , 0.59503844, 0.54187513,\n",
       "       0.55002426, 0.533726  , 0.52446816, 0.54542304, 0.55883859,\n",
       "       0.54120992, 0.53577719, 0.52297136, 0.52485625, 0.53034438,\n",
       "       0.51970064, 0.47889958, 0.45517289, 0.47873328, 0.49896755,\n",
       "       0.50063057, 0.49525325, 0.46565033, 0.46747974, 0.45949691,\n",
       "       0.45594899, 0.48172688, 0.45617079, 0.47851157, 0.48594001,\n",
       "       0.48654981, 0.4839443 , 0.50545358, 0.51753863, 0.53355969,\n",
       "       0.51698432, 0.49176082, 0.55240806, 0.53910331, 0.52419096,\n",
       "       0.49303583, 0.4589426 , 0.45617079, 0.4591643 , 0.46237961,\n",
       "       0.43671262, 0.50323608, 0.51892454, 0.5110526 , 0.52080935,\n",
       "       0.51387982, 0.52457905, 0.52773887, 0.5095558 , 0.52158545,\n",
       "       0.52651936, 0.5101102 , 0.48854551, 0.47163745, 0.5096667 ,\n",
       "       0.51121891, 0.50844709, 0.50190566, 0.48128338, 0.47036244,\n",
       "       0.47984199, 0.47712567, 0.49004232, 0.49547504, 0.48294649,\n",
       "       0.44574875, 0.43471691, 0.42285357, 0.42246556, 0.43992793,\n",
       "       0.42207746, 0.42002635, 0.40988151, 0.38776247, 0.4075532 ,\n",
       "       0.40932712, 0.38238515, 0.38953643, 0.38210796, 0.40760861,\n",
       "       0.41054672, 0.41376203, 0.42906248, 0.42861898, 0.43610282,\n",
       "       0.44264434, 0.43859752, 0.43893012, 0.45334348, 0.47130485,\n",
       "       0.47917678, 0.47546256, 0.4871042 , 0.49802506, 0.48178229,\n",
       "       0.48893352, 0.49525325, 0.52513345, 0.54553394, 0.53017808,\n",
       "       0.54636545, 0.53123138, 0.52541056, 0.52618667, 0.54193062,\n",
       "       0.53832721, 0.55013515, 0.54115451, 0.53472389, 0.51216131,\n",
       "       0.51454511, 0.51726143, 0.50234916, 0.5090569 , 0.50622968,\n",
       "       0.49458804, 0.49791425, 0.52629756, 0.54181972, 0.52945747])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 100), (700,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 100, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Deep learning Projects\\DLenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(100, 1)))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss= 'mean_squared_error', optimizer ='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,851</span> (198.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,851\u001b[0m (198.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,851</span> (198.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,851\u001b[0m (198.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.0000e+00 - loss: 0.0914 - val_accuracy: 0.0030 - val_loss: 0.0500\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.0000e+00 - loss: 0.0096 - val_accuracy: 0.0030 - val_loss: 0.0063\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0030 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.0000e+00 - loss: 0.0034 - val_accuracy: 0.0030 - val_loss: 0.0112\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.0000e+00 - loss: 0.0026 - val_accuracy: 0.0030 - val_loss: 0.0136\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.0000e+00 - loss: 0.0022 - val_accuracy: 0.0030 - val_loss: 0.0110\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.0000e+00 - loss: 0.0019 - val_accuracy: 0.0030 - val_loss: 0.0078\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.0000e+00 - loss: 0.0017 - val_accuracy: 0.0030 - val_loss: 0.0061\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.0000e+00 - loss: 0.0017 - val_accuracy: 0.0030 - val_loss: 0.0052\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.0000e+00 - loss: 0.0016 - val_accuracy: 0.0030 - val_loss: 0.0036\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.0000e+00 - loss: 0.0017 - val_accuracy: 0.0030 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0000e+00 - loss: 0.0016 - val_accuracy: 0.0030 - val_loss: 0.0038\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.0000e+00 - loss: 0.0016 - val_accuracy: 0.0030 - val_loss: 0.0034\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.0000e+00 - loss: 0.0016 - val_accuracy: 0.0030 - val_loss: 0.0032\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - accuracy: 0.0000e+00 - loss: 0.0015 - val_accuracy: 0.0030 - val_loss: 0.0038\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.0000e+00 - loss: 0.0015 - val_accuracy: 0.0030 - val_loss: 0.0028\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - accuracy: 0.0000e+00 - loss: 0.0016 - val_accuracy: 0.0030 - val_loss: 0.0026\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.0000e+00 - loss: 0.0017 - val_accuracy: 0.0030 - val_loss: 0.0033\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.0000e+00 - loss: 0.0014 - val_accuracy: 0.0030 - val_loss: 0.0025\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.0000e+00 - loss: 0.0015 - val_accuracy: 0.0030 - val_loss: 0.0019\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.0000e+00 - loss: 0.0015 - val_accuracy: 0.0030 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.0000e+00 - loss: 0.0013 - val_accuracy: 0.0030 - val_loss: 0.0040\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - accuracy: 0.0000e+00 - loss: 0.0014 - val_accuracy: 0.0030 - val_loss: 0.0025\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.0000e+00 - loss: 0.0013 - val_accuracy: 0.0030 - val_loss: 0.0024\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.0000e+00 - loss: 0.0012 - val_accuracy: 0.0030 - val_loss: 0.0043\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.0000e+00 - loss: 0.0014 - val_accuracy: 0.0030 - val_loss: 0.0018\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.0000e+00 - loss: 0.0013 - val_accuracy: 0.0030 - val_loss: 0.0028\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.0000e+00 - loss: 0.0012 - val_accuracy: 0.0030 - val_loss: 0.0024\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0028\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.0000e+00 - loss: 0.0012 - val_accuracy: 0.0030 - val_loss: 0.0021\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.0000e+00 - loss: 0.0010 - val_accuracy: 0.0030 - val_loss: 0.0041\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0016\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0052\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.0000e+00 - loss: 0.0012 - val_accuracy: 0.0030 - val_loss: 0.0030\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.0000e+00 - loss: 0.0012 - val_accuracy: 0.0030 - val_loss: 0.0020\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0061\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0016\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 476ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0028\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - accuracy: 0.0000e+00 - loss: 0.0011 - val_accuracy: 0.0030 - val_loss: 0.0029\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - accuracy: 0.0000e+00 - loss: 9.0469e-04 - val_accuracy: 0.0030 - val_loss: 0.0039\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.0000e+00 - loss: 9.2492e-04 - val_accuracy: 0.0030 - val_loss: 0.0029\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.0000e+00 - loss: 7.6300e-04 - val_accuracy: 0.0030 - val_loss: 0.0021\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.0000e+00 - loss: 9.0089e-04 - val_accuracy: 0.0030 - val_loss: 0.0025\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.0000e+00 - loss: 9.0081e-04 - val_accuracy: 0.0030 - val_loss: 0.0035\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: 9.4670e-04 - val_accuracy: 0.0030 - val_loss: 0.0023\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 9.3228e-04 - val_accuracy: 0.0030 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 8.2860e-04 - val_accuracy: 0.0030 - val_loss: 0.0038\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0000e+00 - loss: 0.0010 - val_accuracy: 0.0030 - val_loss: 0.0022\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 8.4354e-04 - val_accuracy: 0.0030 - val_loss: 0.0020\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.0000e+00 - loss: 7.9610e-04 - val_accuracy: 0.0030 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 7.9488e-04 - val_accuracy: 0.0030 - val_loss: 0.0021\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 7.0419e-04 - val_accuracy: 0.0030 - val_loss: 0.0023\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 7.9626e-04 - val_accuracy: 0.0030 - val_loss: 0.0017\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 7.7458e-04 - val_accuracy: 0.0030 - val_loss: 9.4826e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 7.5832e-04 - val_accuracy: 0.0030 - val_loss: 0.0012\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: 7.3385e-04 - val_accuracy: 0.0030 - val_loss: 0.0015\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0000e+00 - loss: 6.6180e-04 - val_accuracy: 0.0030 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 6.9161e-04 - val_accuracy: 0.0030 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.0000e+00 - loss: 6.7159e-04 - val_accuracy: 0.0030 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 7.1898e-04 - val_accuracy: 0.0030 - val_loss: 0.0034\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 8.1872e-04 - val_accuracy: 0.0030 - val_loss: 0.0039\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 0.0010 - val_accuracy: 0.0030 - val_loss: 8.2397e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.0000e+00 - loss: 9.4833e-04 - val_accuracy: 0.0030 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 6.7515e-04 - val_accuracy: 0.0030 - val_loss: 9.6203e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 7.3119e-04 - val_accuracy: 0.0030 - val_loss: 0.0011\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: 6.1597e-04 - val_accuracy: 0.0030 - val_loss: 0.0014\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 6.6345e-04 - val_accuracy: 0.0030 - val_loss: 8.2203e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 6.1102e-04 - val_accuracy: 0.0030 - val_loss: 0.0016\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.0000e+00 - loss: 6.2325e-04 - val_accuracy: 0.0030 - val_loss: 7.5941e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 6.8629e-04 - val_accuracy: 0.0030 - val_loss: 7.1657e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.0000e+00 - loss: 6.1831e-04 - val_accuracy: 0.0030 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 5.1973e-04 - val_accuracy: 0.0030 - val_loss: 7.9752e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0000e+00 - loss: 5.7098e-04 - val_accuracy: 0.0030 - val_loss: 0.0013\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 5.9849e-04 - val_accuracy: 0.0030 - val_loss: 8.4213e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 5.5704e-04 - val_accuracy: 0.0030 - val_loss: 7.5652e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 5.8831e-04 - val_accuracy: 0.0030 - val_loss: 6.0556e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0000e+00 - loss: 6.1633e-04 - val_accuracy: 0.0030 - val_loss: 7.4052e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 7.1682e-04 - val_accuracy: 0.0030 - val_loss: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 9.6513e-04 - val_accuracy: 0.0030 - val_loss: 7.3025e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 6.3825e-04 - val_accuracy: 0.0030 - val_loss: 0.0024\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 6.4024e-04 - val_accuracy: 0.0030 - val_loss: 6.0760e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 5.2328e-04 - val_accuracy: 0.0030 - val_loss: 6.6020e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.0000e+00 - loss: 5.3651e-04 - val_accuracy: 0.0030 - val_loss: 0.0017\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 5.1765e-04 - val_accuracy: 0.0030 - val_loss: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 5.3095e-04 - val_accuracy: 0.0030 - val_loss: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 4.8949e-04 - val_accuracy: 0.0030 - val_loss: 5.3356e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0000e+00 - loss: 4.8771e-04 - val_accuracy: 0.0030 - val_loss: 9.6120e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 5.3661e-04 - val_accuracy: 0.0030 - val_loss: 6.4831e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: 5.2578e-04 - val_accuracy: 0.0030 - val_loss: 5.9495e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 5.4512e-04 - val_accuracy: 0.0030 - val_loss: 7.5128e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 5.2003e-04 - val_accuracy: 0.0030 - val_loss: 0.0015\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 5.7853e-04 - val_accuracy: 0.0030 - val_loss: 9.8245e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 5.2255e-04 - val_accuracy: 0.0030 - val_loss: 6.0493e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 5.7191e-04 - val_accuracy: 0.0030 - val_loss: 7.7834e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 4.8387e-04 - val_accuracy: 0.0030 - val_loss: 0.0016\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.0000e+00 - loss: 5.5059e-04 - val_accuracy: 0.0030 - val_loss: 5.1463e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.0000e+00 - loss: 4.6486e-04 - val_accuracy: 0.0030 - val_loss: 9.9952e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: 4.4496e-04 - val_accuracy: 0.0030 - val_loss: 9.2132e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 4.6728e-04 - val_accuracy: 0.0030 - val_loss: 4.7256e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f76e6fed50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 7.6394e-04 - loss: 4.9544e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0004725594772025943, 0.003021148033440113]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predict= model.predict(X_train)\n",
    "test_predict =model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = scalar.inverse_transform(train_predict)\n",
    "test_predict = scalar.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.0363401303782"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train, train_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.07853594546668"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
